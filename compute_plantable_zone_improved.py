"""
compute_plantable_zone.py - VERSION AM√âLIOR√âE

Analyse stricte des zones plantables avec filtres pour exclure :
- Murs et fa√ßades (position haute + vertical)
- Mobilier (chaises, tables)
- Structures non-sol (bbox ratio)
"""

import json
import numpy as np
import cv2
from pycocotools import mask as mask_utils
from pathlib import Path
from typing import List, Tuple, Dict


# ============ Configuration AM√âLIOR√âE ============
VISION_JSON = Path("VisionOutput.json")
IMAGE_PATH = Path("Inputs/IMG_5177-535x356_preprocessed.jpg")
OUT_JSON = Path("PlantableZone.json")

# Seuils STRICTS pour √©viter les faux positifs
CONFIG = {
    "position": {
        "min_y_centroid": 0.55,  # ‚¨ÜÔ∏è Plus strict : seulement bas de l'image
        "min_y_bbox": 0.50,      # ‚¨ÜÔ∏è NOUVEAU : bbox doit commencer assez bas
    },
    "depth": {
        "allowed_bands": ["front", "mid"],
        "max_mean_depth": 0.85,  # ‚¨ÜÔ∏è NOUVEAU : exclure premier plan trop proche (objets)
        "min_mean_depth": 0.25,  # ‚¨ÜÔ∏è NOUVEAU : exclure arri√®re-plan trop loin
    },
    "color": {
        "min_green_ratio": 0.35,      # ‚¨ÜÔ∏è Plus strict
        "min_brown_ratio": 0.25,      # ‚¨ÜÔ∏è Plus strict
        "max_gray_ratio": 0.6,        # ‚¨ÜÔ∏è NOUVEAU : exclure murs gris/beiges
        "require_saturation": True,   # ‚¨ÜÔ∏è NOUVEAU : n√©cessite couleur satur√©e
        "min_saturation": 30,         # ‚¨ÜÔ∏è NOUVEAU : seuil HSV saturation
    },
    "shape": {
        "max_aspect_ratio": 3.0,      # ‚¨ÜÔ∏è NOUVEAU : exclure formes tr√®s allong√©es (murs)
        "min_area_ratio": 0.008,      # ‚¨ÜÔ∏è Plus strict : 0.8% minimum
        "max_area_ratio": 0.35,       # ‚¨ÜÔ∏è NOUVEAU : exclure zones trop grandes (ciel, murs)
    },
    "texture": {
        "check_edge_density": True,   # ‚¨ÜÔ∏è NOUVEAU : d√©tecter structures artificielles
        "max_edge_ratio": 0.3,        # ‚¨ÜÔ∏è NOUVEAU : max 30% de contours (mobilier)
    },
    "anchors": {
        "num_points": 15,
    }
}


def compute_color_features(img: np.ndarray, mask: np.ndarray) -> Dict:
    """
    Analyse couleur AM√âLIOR√âE avec d√©tection de saturation et gris.
    """
    pixels = img[mask]
    
    if len(pixels) == 0:
        return {
            "mean_rgb": [0, 0, 0],
            "mean_hsv": [0, 0, 0],
            "green_ratio": 0.0,
            "brown_ratio": 0.0,
            "gray_ratio": 0.0,
            "mean_saturation": 0.0
        }
    
    # RGB moyen
    mean_rgb = pixels.mean(axis=0).tolist()
    
    # HSV
    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
    pixels_hsv = img_hsv[mask]
    mean_hsv = pixels_hsv.mean(axis=0).tolist()
    
    # Saturation moyenne (important pour distinguer v√©g√©tation de murs)
    mean_saturation = float(pixels_hsv[:, 1].mean())
    
    # D√©tection VERT (v√©g√©tation) - crit√®res stricts
    green_mask = (
        (pixels_hsv[:, 0] >= 35) & (pixels_hsv[:, 0] <= 85) &  # Teinte verte
        (pixels_hsv[:, 1] > 30) &   # Saturation minimum (pas gris)
        (pixels_hsv[:, 2] > 30)     # Luminosit√© minimum
    )
    green_ratio = green_mask.sum() / len(pixels)
    
    # D√©tection BRUN (sol/terre) - crit√®res stricts
    brown_mask = (
        (pixels_hsv[:, 0] >= 10) & (pixels_hsv[:, 0] <= 30) &  # Teinte brun/orange
        (pixels_hsv[:, 1] > 25) &   # Saturation minimum
        (pixels_hsv[:, 2] > 20) & (pixels_hsv[:, 2] < 120)  # Luminosit√© mod√©r√©e
    )
    brown_ratio = brown_mask.sum() / len(pixels)
    
    # D√©tection GRIS/BEIGE (murs, structures) - √Ä EXCLURE
    gray_mask = (
        (pixels_hsv[:, 1] < 30) |   # Faible saturation = gris
        (
            (pixels_hsv[:, 0] >= 15) & (pixels_hsv[:, 0] <= 35) &  # Teinte beige
            (pixels_hsv[:, 1] < 40) &  # Saturation faible
            (pixels_hsv[:, 2] > 80)    # Luminosit√© haute (murs clairs)
        )
    )
    gray_ratio = gray_mask.sum() / len(pixels)
    
    return {
        "mean_rgb": [float(x) for x in mean_rgb],
        "mean_hsv": [float(x) for x in mean_hsv],
        "green_ratio": float(green_ratio),
        "brown_ratio": float(brown_ratio),
        "gray_ratio": float(gray_ratio),
        "mean_saturation": mean_saturation
    }


def compute_shape_features(segment: Dict, H: int, W: int) -> Dict:
    """
    Calcule features g√©om√©triques pour d√©tecter murs et structures.
    """
    bbox = segment.get("bbox", [0, 0, 1, 1])  # [x, y, w, h] normalis√©
    
    # Dimensions en pixels
    bbox_w = bbox[2] * W
    bbox_h = bbox[3] * H
    
    # Aspect ratio : hauteur/largeur (>1 = vertical, <1 = horizontal)
    if bbox_w > 0:
        aspect_ratio = bbox_h / bbox_w
    else:
        aspect_ratio = 0
    
    # Position bbox
    bbox_y_start = bbox[1]
    bbox_y_end = bbox[1] + bbox[3]
    
    return {
        "aspect_ratio": float(aspect_ratio),
        "bbox_y_start": float(bbox_y_start),
        "bbox_y_end": float(bbox_y_end),
        "bbox_width": float(bbox_w),
        "bbox_height": float(bbox_h)
    }


def compute_texture_features(img: np.ndarray, mask: np.ndarray) -> Dict:
    """
    Analyse de texture pour d√©tecter structures artificielles (mobilier, fen√™tres).
    """
    if mask.sum() == 0:
        return {"edge_ratio": 0.0}
    
    # Cr√©er une sous-image du segment
    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    
    # D√©tection de contours (Canny)
    edges = cv2.Canny(img_gray, 50, 150)
    
    # Compter les pixels de contours dans le masque
    edge_pixels = edges[mask].sum() / 255  # Normaliser
    total_pixels = mask.sum()
    
    edge_ratio = edge_pixels / total_pixels if total_pixels > 0 else 0
    
    return {
        "edge_ratio": float(edge_ratio)
    }


def is_plantable(
    segment: Dict,
    color_features: Dict,
    shape_features: Dict,
    texture_features: Dict,
    config: Dict
) -> Tuple[bool, List[str]]:
    """
    D√©termine si un segment est plantable avec crit√®res STRICTS.
    """
    reasons = []
    
    # ===== CRIT√àRE 1 : Position (BAS de l'image) =====
    centroid_y = segment.get("centroid", [0, 0])[1]
    bbox_y_start = shape_features["bbox_y_start"]
    
    if centroid_y < config["position"]["min_y_centroid"]:
        reasons.append(f"position_too_high (centroid_y={centroid_y:.2f})")
    
    if bbox_y_start < config["position"]["min_y_bbox"]:
        reasons.append(f"bbox_starts_too_high (y={bbox_y_start:.2f})")
    
    # ===== CRIT√àRE 2 : Profondeur (ni trop proche, ni trop loin) =====
    depth_band = segment.get("depth_band")
    mean_depth = segment.get("mean_depth", 0)
    
    if depth_band not in config["depth"]["allowed_bands"]:
        reasons.append(f"depth_band_invalid (band={depth_band})")
    
    if mean_depth > config["depth"]["max_mean_depth"]:
        reasons.append(f"depth_too_close (depth={mean_depth:.2f}, objects)")
    
    if mean_depth < config["depth"]["min_mean_depth"]:
        reasons.append(f"depth_too_far (depth={mean_depth:.2f}, background)")
    
    # ===== CRIT√àRE 3 : Couleur (VERT ou BRUN, pas GRIS) =====
    green_ratio = color_features["green_ratio"]
    brown_ratio = color_features["brown_ratio"]
    gray_ratio = color_features["gray_ratio"]
    saturation = color_features["mean_saturation"]
    
    is_green = green_ratio >= config["color"]["min_green_ratio"]
    is_brown = brown_ratio >= config["color"]["min_brown_ratio"]
    
    if not (is_green or is_brown):
        reasons.append(f"color_not_vegetation (green={green_ratio:.2f}, brown={brown_ratio:.2f})")
    
    if gray_ratio > config["color"]["max_gray_ratio"]:
        reasons.append(f"too_much_gray (gray={gray_ratio:.2f}, likely wall/structure)")
    
    if config["color"]["require_saturation"] and saturation < config["color"]["min_saturation"]:
        reasons.append(f"low_saturation (sat={saturation:.1f}, likely gray surface)")
    
    # ===== CRIT√àRE 4 : Forme (pas trop vertical = mur, pas trop grand) =====
    area_ratio = segment.get("area_ratio", 0)
    aspect_ratio = shape_features["aspect_ratio"]
    
    if area_ratio < config["shape"]["min_area_ratio"]:
        reasons.append(f"too_small (area={area_ratio:.4f})")
    
    if area_ratio > config["shape"]["max_area_ratio"]:
        reasons.append(f"too_large (area={area_ratio:.2f}, likely wall/sky)")
    
    if aspect_ratio > config["shape"]["max_aspect_ratio"]:
        reasons.append(f"too_vertical (ratio={aspect_ratio:.1f}, likely wall/tree)")
    
    # ===== CRIT√àRE 5 : Texture (pas trop de contours = mobilier) =====
    if config["texture"]["check_edge_density"]:
        edge_ratio = texture_features["edge_ratio"]
        if edge_ratio > config["texture"]["max_edge_ratio"]:
            reasons.append(f"high_edge_density (edges={edge_ratio:.2f}, likely furniture)")
    
    is_plantable = len(reasons) == 0
    
    return is_plantable, reasons


def generate_anchor_points(mask: np.ndarray, num_points: int) -> List[List[float]]:
    """G√©n√®re des points d'ancrage uniform√©ment r√©partis."""
    H, W = mask.shape
    y_coords, x_coords = np.where(mask)
    
    if len(x_coords) == 0:
        return []
    
    total_pixels = len(x_coords)
    if total_pixels <= num_points:
        indices = np.arange(total_pixels)
    else:
        indices = np.linspace(0, total_pixels - 1, num_points, dtype=int)
    
    anchors = []
    for idx in indices:
        x_norm = float(x_coords[idx]) / W
        y_norm = float(y_coords[idx]) / H
        anchors.append([x_norm, y_norm])
    
    return anchors


def main():
    print("=" * 70)
    print("PLANTABLE ZONE COMPUTATION - VERSION AM√âLIOR√âE")
    print("=" * 70)
    
    # Load data
    print(f"\nLoading {VISION_JSON}...")
    with open(VISION_JSON, "r", encoding="utf-8") as f:
        vision = json.load(f)
    
    print(f"Loading {IMAGE_PATH}...")
    img = cv2.imread(str(IMAGE_PATH))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    H, W, _ = img.shape
    
    segments = vision.get("segments", [])
    print(f"Total segments: {len(segments)}")
    
    # Analyse each segment
    print("\nüîç Analyzing segments with STRICT criteria...")
    plantable_segments = []
    plantable_mask_combined = np.zeros((H, W), dtype=bool)
    
    segment_details = []
    
    for seg in segments:
        seg_id = seg["segment_id"]
        rle = seg["mask_rle"]
        mask = mask_utils.decode(rle).astype(bool)
        
        # Compute all features
        color_features = compute_color_features(img, mask)
        shape_features = compute_shape_features(seg, H, W)
        texture_features = compute_texture_features(img, mask)
        
        # Check plantability
        is_plant, reasons = is_plantable(seg, color_features, shape_features, texture_features, CONFIG)
        
        detail = {
            "segment_id": seg_id,
            "area_ratio": seg.get("area_ratio"),
            "centroid": seg.get("centroid"),
            "depth_band": seg.get("depth_band"),
            "mean_depth": seg.get("mean_depth"),
            "color_features": color_features,
            "shape_features": shape_features,
            "texture_features": texture_features,
            "is_plantable": is_plant,
            "rejection_reasons": reasons if not is_plant else []
        }
        segment_details.append(detail)
        
        if is_plant:
            plantable_segments.append(seg_id)
            plantable_mask_combined |= mask
            print(f"  ‚úÖ Segment {seg_id}: PLANTABLE")
        else:
            print(f"  ‚ùå Segment {seg_id}: {reasons[0] if reasons else 'unknown'}")
    
    print(f"\n‚úÖ Plantable segments: {len(plantable_segments)} / {len(segments)}")
    
    # Coverage
    total_pixels = H * W
    plantable_pixels = plantable_mask_combined.sum()
    coverage = float(plantable_pixels) / total_pixels
    
    print(f"‚úÖ Plantable coverage: {coverage:.2%}")
    
    # Anchor points
    print(f"\nGenerating {CONFIG['anchors']['num_points']} anchor points...")
    anchors = generate_anchor_points(plantable_mask_combined, CONFIG["anchors"]["num_points"])
    print(f"‚úÖ Generated {len(anchors)} anchors")
    
    # Encode mask
    plantable_rle = mask_utils.encode(np.asfortranarray(plantable_mask_combined.astype(np.uint8)))
    plantable_rle["counts"] = plantable_rle["counts"].decode("utf-8")
    
    # Build output
    output = {
        "version": "plantable_zone_v2_strict",
        "image_id": vision.get("image_id"),
        "image_size": [W, H],
        
        "config": CONFIG,
        
        "plantable": {
            "segments_count": len(plantable_segments),
            "segment_ids": plantable_segments,
            "coverage": coverage,
            "total_pixels": int(plantable_pixels),
            "mask_rle": plantable_rle,
            "anchors": anchors
        },
        
        "segment_analysis": segment_details
    }
    
    with open(OUT_JSON, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2)
    
    print(f"\n‚úÖ Saved {OUT_JSON}")
    
    # Summary
    print("\n" + "=" * 70)
    print("SUMMARY - STRICT FILTERING")
    print("=" * 70)
    print(f"Total segments:       {len(segments)}")
    print(f"Plantable segments:   {len(plantable_segments)} ({len(plantable_segments)/len(segments):.1%})")
    print(f"Plantable coverage:   {coverage:.2%}")
    print(f"Anchor points:        {len(anchors)}")
    
    # Rejection statistics
    print("\nüìä Rejection reasons breakdown:")
    rejection_stats = {}
    for detail in segment_details:
        if not detail["is_plantable"]:
            for reason in detail["rejection_reasons"]:
                reason_key = reason.split("(")[0].strip()
                rejection_stats[reason_key] = rejection_stats.get(reason_key, 0) + 1
    
    for reason, count in sorted(rejection_stats.items(), key=lambda x: -x[1]):
        print(f"  - {reason}: {count}")


if __name__ == "__main__":
    main()
